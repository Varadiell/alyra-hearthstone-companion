{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35867 entries, 0 to 35866\n",
      "Columns: 1275 entries, deck_archetype to Murloc Holmes\n",
      "dtypes: int64(1274), object(1)\n",
      "memory usage: 348.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Import the data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/priest_popular_archetype_decks.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deck_archetype</th>\n",
       "      <th>Circle of Healing</th>\n",
       "      <th>Flash Heal</th>\n",
       "      <th>Northshire Cleric</th>\n",
       "      <th>Power Word: Shield</th>\n",
       "      <th>Embrace the Shadow</th>\n",
       "      <th>Mind Blast</th>\n",
       "      <th>Shadow Word: Death</th>\n",
       "      <th>Shadow Word: Pain</th>\n",
       "      <th>Auchenai Soulpriest</th>\n",
       "      <th>...</th>\n",
       "      <th>Coilfang Constrictor</th>\n",
       "      <th>Snapdragon</th>\n",
       "      <th>Neptulon the Tidehunter</th>\n",
       "      <th>Ozumat</th>\n",
       "      <th>Prince Renathal</th>\n",
       "      <th>Ethereal Augmerchant</th>\n",
       "      <th>Replicat-o-tron</th>\n",
       "      <th>Cathedral of Atonement</th>\n",
       "      <th>Dispossessed Soul</th>\n",
       "      <th>Murloc Holmes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Control Priest</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dragon Priest</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Control Priest</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dragon Priest</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C'Thun Priest</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1275 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   deck_archetype  Circle of Healing  Flash Heal  Northshire Cleric  \\\n",
       "0  Control Priest                  2           2                  2   \n",
       "1   Dragon Priest                  0           0                  2   \n",
       "2  Control Priest                  2           0                  2   \n",
       "3   Dragon Priest                  0           0                  2   \n",
       "4   C'Thun Priest                  0           0                  2   \n",
       "\n",
       "   Power Word: Shield  Embrace the Shadow  Mind Blast  Shadow Word: Death  \\\n",
       "0                   2                   2           2                   1   \n",
       "1                   2                   0           0                   1   \n",
       "2                   2                   0           0                   2   \n",
       "3                   2                   0           0                   2   \n",
       "4                   2                   0           0                   0   \n",
       "\n",
       "   Shadow Word: Pain  Auchenai Soulpriest  ...  Coilfang Constrictor  \\\n",
       "0                  1                    2  ...                     0   \n",
       "1                  0                    0  ...                     0   \n",
       "2                  0                    2  ...                     0   \n",
       "3                  1                    0  ...                     0   \n",
       "4                  0                    0  ...                     0   \n",
       "\n",
       "   Snapdragon  Neptulon the Tidehunter  Ozumat  Prince Renathal  \\\n",
       "0           0                        0       0                0   \n",
       "1           0                        0       0                0   \n",
       "2           0                        0       0                0   \n",
       "3           0                        0       0                0   \n",
       "4           0                        0       0                0   \n",
       "\n",
       "   Ethereal Augmerchant  Replicat-o-tron  Cathedral of Atonement  \\\n",
       "0                     0                0                       0   \n",
       "1                     0                0                       0   \n",
       "2                     0                0                       0   \n",
       "3                     0                0                       0   \n",
       "4                     0                0                       0   \n",
       "\n",
       "   Dispossessed Soul  Murloc Holmes  \n",
       "0                  0              0  \n",
       "1                  0              0  \n",
       "2                  0              0  \n",
       "3                  0              0  \n",
       "4                  0              0  \n",
       "\n",
       "[5 rows x 1275 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Input (X) and Output (y)\n",
    "X = df.drop(columns=['deck_archetype'])\n",
    "y = df['deck_archetype']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Labels (deck_archetype)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data for training\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build Neural Network Model\n",
    "# Note: have to use python 3.12.8 because tensorflow does not yet handle versions above this one.\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(512, activation='relu', input_shape=(X_train.shape[1],), kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.45), # Prevent overfitting\n",
    "    keras.layers.Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.40),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dropout(0.35),\n",
    "    keras.layers.Dense(len(encoder.classes_), activation='softmax') # Multi-class output\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.4654 - loss: 8.9897 - val_accuracy: 0.7136 - val_loss: 4.0410\n",
      "Epoch 2/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6748 - loss: 3.5641 - val_accuracy: 0.7258 - val_loss: 2.1308\n",
      "Epoch 3/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7028 - loss: 2.0204 - val_accuracy: 0.7254 - val_loss: 1.4880\n",
      "Epoch 4/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7058 - loss: 1.5171 - val_accuracy: 0.7320 - val_loss: 1.2944\n",
      "Epoch 5/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7180 - loss: 1.3258 - val_accuracy: 0.7270 - val_loss: 1.2436\n",
      "Epoch 6/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7106 - loss: 1.2935 - val_accuracy: 0.7396 - val_loss: 1.2020\n",
      "Epoch 7/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7213 - loss: 1.2616 - val_accuracy: 0.7356 - val_loss: 1.1938\n",
      "Epoch 8/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7136 - loss: 1.2666 - val_accuracy: 0.7295 - val_loss: 1.2097\n",
      "Epoch 9/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7255 - loss: 1.2472 - val_accuracy: 0.7367 - val_loss: 1.1898\n",
      "Epoch 10/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7185 - loss: 1.2560 - val_accuracy: 0.7344 - val_loss: 1.1734\n",
      "Epoch 11/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7182 - loss: 1.2460 - val_accuracy: 0.7304 - val_loss: 1.2064\n",
      "Epoch 12/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7135 - loss: 1.2554 - val_accuracy: 0.7361 - val_loss: 1.1686\n",
      "Epoch 13/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7204 - loss: 1.2357 - val_accuracy: 0.7346 - val_loss: 1.1871\n",
      "Epoch 14/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7194 - loss: 1.2271 - val_accuracy: 0.7334 - val_loss: 1.1852\n",
      "Epoch 15/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7231 - loss: 1.2266 - val_accuracy: 0.7295 - val_loss: 1.1740\n",
      "Epoch 16/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7241 - loss: 1.2165 - val_accuracy: 0.7338 - val_loss: 1.1813\n",
      "Epoch 17/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7218 - loss: 1.2201 - val_accuracy: 0.7322 - val_loss: 1.1794\n",
      "Epoch 18/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7179 - loss: 1.2216 - val_accuracy: 0.7347 - val_loss: 1.1729\n",
      "Epoch 19/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7234 - loss: 1.2114 - val_accuracy: 0.7435 - val_loss: 1.1590\n",
      "Epoch 20/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7275 - loss: 1.2081 - val_accuracy: 0.7206 - val_loss: 1.1823\n",
      "Epoch 21/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7174 - loss: 1.2123 - val_accuracy: 0.7386 - val_loss: 1.1750\n",
      "Epoch 22/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7268 - loss: 1.1990 - val_accuracy: 0.7292 - val_loss: 1.1597\n",
      "Epoch 23/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7270 - loss: 1.1921 - val_accuracy: 0.7359 - val_loss: 1.1638\n",
      "Epoch 24/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7268 - loss: 1.1908 - val_accuracy: 0.7258 - val_loss: 1.1642\n",
      "Epoch 25/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7330 - loss: 1.1874 - val_accuracy: 0.7307 - val_loss: 1.1544\n",
      "Epoch 26/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7273 - loss: 1.1693 - val_accuracy: 0.7326 - val_loss: 1.1533\n",
      "Epoch 27/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7244 - loss: 1.1886 - val_accuracy: 0.7377 - val_loss: 1.1570\n",
      "Epoch 28/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7272 - loss: 1.1779 - val_accuracy: 0.7410 - val_loss: 1.1280\n",
      "Epoch 29/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7344 - loss: 1.1529 - val_accuracy: 0.7307 - val_loss: 1.1447\n",
      "Epoch 30/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7258 - loss: 1.1816 - val_accuracy: 0.7277 - val_loss: 1.1444\n",
      "Epoch 31/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7340 - loss: 1.1546 - val_accuracy: 0.7353 - val_loss: 1.1355\n",
      "Epoch 32/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7206 - loss: 1.1792 - val_accuracy: 0.7310 - val_loss: 1.1299\n",
      "Epoch 33/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7307 - loss: 1.1573 - val_accuracy: 0.7329 - val_loss: 1.1375\n",
      "Epoch 34/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7173 - loss: 1.1658 - val_accuracy: 0.7334 - val_loss: 1.1308\n",
      "Epoch 35/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7272 - loss: 1.1566 - val_accuracy: 0.7439 - val_loss: 1.1283\n",
      "Epoch 36/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7269 - loss: 1.1696 - val_accuracy: 0.7426 - val_loss: 1.1164\n",
      "Epoch 37/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7273 - loss: 1.1540 - val_accuracy: 0.7347 - val_loss: 1.1212\n",
      "Epoch 38/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7266 - loss: 1.1560 - val_accuracy: 0.7350 - val_loss: 1.1052\n",
      "Epoch 39/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7309 - loss: 1.1486 - val_accuracy: 0.7337 - val_loss: 1.1206\n",
      "Epoch 40/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7283 - loss: 1.1582 - val_accuracy: 0.7375 - val_loss: 1.1151\n",
      "Epoch 41/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7250 - loss: 1.1547 - val_accuracy: 0.7350 - val_loss: 1.1179\n",
      "Epoch 42/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7318 - loss: 1.1268 - val_accuracy: 0.7377 - val_loss: 1.1136\n",
      "Epoch 43/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7327 - loss: 1.1269 - val_accuracy: 0.7383 - val_loss: 1.1078\n",
      "Epoch 44/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7305 - loss: 1.1372 - val_accuracy: 0.7358 - val_loss: 1.1016\n",
      "Epoch 45/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7359 - loss: 1.1179 - val_accuracy: 0.7358 - val_loss: 1.1101\n",
      "Epoch 46/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7336 - loss: 1.1274 - val_accuracy: 0.7344 - val_loss: 1.0991\n",
      "Epoch 47/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7272 - loss: 1.1301 - val_accuracy: 0.7404 - val_loss: 1.0927\n",
      "Epoch 48/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7262 - loss: 1.1453 - val_accuracy: 0.7399 - val_loss: 1.0940\n",
      "Epoch 49/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7357 - loss: 1.1032 - val_accuracy: 0.7389 - val_loss: 1.0891\n",
      "Epoch 50/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7273 - loss: 1.1236 - val_accuracy: 0.7356 - val_loss: 1.1015\n",
      "Epoch 51/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7275 - loss: 1.1267 - val_accuracy: 0.7398 - val_loss: 1.0856\n",
      "Epoch 52/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7289 - loss: 1.1245 - val_accuracy: 0.7411 - val_loss: 1.0850\n",
      "Epoch 53/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7265 - loss: 1.1272 - val_accuracy: 0.7442 - val_loss: 1.0784\n",
      "Epoch 54/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7358 - loss: 1.1043 - val_accuracy: 0.7381 - val_loss: 1.0786\n",
      "Epoch 55/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7377 - loss: 1.1028 - val_accuracy: 0.7411 - val_loss: 1.0852\n",
      "Epoch 56/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7295 - loss: 1.1219 - val_accuracy: 0.7384 - val_loss: 1.0872\n",
      "Epoch 57/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7318 - loss: 1.1154 - val_accuracy: 0.7304 - val_loss: 1.1064\n",
      "Epoch 58/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7341 - loss: 1.1147 - val_accuracy: 0.7375 - val_loss: 1.0953\n",
      "Epoch 59/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7259 - loss: 1.1124 - val_accuracy: 0.7398 - val_loss: 1.0838\n",
      "Epoch 60/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7305 - loss: 1.1069 - val_accuracy: 0.7392 - val_loss: 1.0946\n",
      "Epoch 61/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7256 - loss: 1.1302 - val_accuracy: 0.7340 - val_loss: 1.0910\n",
      "Epoch 62/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7331 - loss: 1.0961 - val_accuracy: 0.7283 - val_loss: 1.1096\n",
      "Epoch 63/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7360 - loss: 1.0977 - val_accuracy: 0.7420 - val_loss: 1.0762\n",
      "Epoch 64/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7315 - loss: 1.1094 - val_accuracy: 0.7402 - val_loss: 1.0781\n",
      "Epoch 65/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7360 - loss: 1.0959 - val_accuracy: 0.7381 - val_loss: 1.0788\n",
      "Epoch 66/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7350 - loss: 1.1017 - val_accuracy: 0.7383 - val_loss: 1.0774\n",
      "Epoch 67/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7314 - loss: 1.0938 - val_accuracy: 0.7372 - val_loss: 1.0791\n",
      "Epoch 68/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7363 - loss: 1.0954 - val_accuracy: 0.7386 - val_loss: 1.0767\n",
      "Epoch 69/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7362 - loss: 1.0921 - val_accuracy: 0.7370 - val_loss: 1.0880\n",
      "Epoch 70/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7293 - loss: 1.1062 - val_accuracy: 0.7447 - val_loss: 1.0647\n",
      "Epoch 71/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7378 - loss: 1.0955 - val_accuracy: 0.7395 - val_loss: 1.0710\n",
      "Epoch 72/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7374 - loss: 1.0904 - val_accuracy: 0.7395 - val_loss: 1.0719\n",
      "Epoch 73/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7386 - loss: 1.0795 - val_accuracy: 0.7288 - val_loss: 1.0806\n",
      "Epoch 74/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7388 - loss: 1.0903 - val_accuracy: 0.7307 - val_loss: 1.0845\n",
      "Epoch 75/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7390 - loss: 1.0771 - val_accuracy: 0.7307 - val_loss: 1.0825\n",
      "Epoch 76/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7294 - loss: 1.1026 - val_accuracy: 0.7358 - val_loss: 1.0633\n",
      "Epoch 77/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7364 - loss: 1.0829 - val_accuracy: 0.7381 - val_loss: 1.0775\n",
      "Epoch 78/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7338 - loss: 1.1005 - val_accuracy: 0.7386 - val_loss: 1.0609\n",
      "Epoch 79/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7289 - loss: 1.0991 - val_accuracy: 0.7398 - val_loss: 1.0769\n",
      "Epoch 80/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7283 - loss: 1.1037 - val_accuracy: 0.7450 - val_loss: 1.0730\n",
      "Epoch 81/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7343 - loss: 1.1015 - val_accuracy: 0.7380 - val_loss: 1.0717\n",
      "Epoch 82/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7381 - loss: 1.0807 - val_accuracy: 0.7338 - val_loss: 1.0745\n",
      "Epoch 83/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7287 - loss: 1.0972 - val_accuracy: 0.7320 - val_loss: 1.0705\n",
      "Epoch 84/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7308 - loss: 1.0881 - val_accuracy: 0.7231 - val_loss: 1.0926\n",
      "Epoch 85/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7302 - loss: 1.0974 - val_accuracy: 0.7432 - val_loss: 1.0559\n",
      "Epoch 86/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7324 - loss: 1.0748 - val_accuracy: 0.7320 - val_loss: 1.0646\n",
      "Epoch 87/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7318 - loss: 1.0820 - val_accuracy: 0.7405 - val_loss: 1.0628\n",
      "Epoch 88/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7257 - loss: 1.0879 - val_accuracy: 0.7364 - val_loss: 1.0592\n",
      "Epoch 89/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7261 - loss: 1.0909 - val_accuracy: 0.7361 - val_loss: 1.0586\n",
      "Epoch 90/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7334 - loss: 1.0794 - val_accuracy: 0.7364 - val_loss: 1.0732\n",
      "Epoch 91/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7362 - loss: 1.0798 - val_accuracy: 0.7378 - val_loss: 1.0671\n",
      "Epoch 92/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7314 - loss: 1.0867 - val_accuracy: 0.7399 - val_loss: 1.0582\n",
      "Epoch 93/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7338 - loss: 1.0651 - val_accuracy: 0.7433 - val_loss: 1.0515\n",
      "Epoch 94/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7280 - loss: 1.0813 - val_accuracy: 0.7375 - val_loss: 1.0701\n",
      "Epoch 95/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7408 - loss: 1.0650 - val_accuracy: 0.7340 - val_loss: 1.0628\n",
      "Epoch 96/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7376 - loss: 1.0720 - val_accuracy: 0.7347 - val_loss: 1.0785\n",
      "Epoch 97/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7366 - loss: 1.0772 - val_accuracy: 0.7361 - val_loss: 1.0754\n",
      "Epoch 98/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7266 - loss: 1.0794 - val_accuracy: 0.7404 - val_loss: 1.0546\n",
      "Epoch 99/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7333 - loss: 1.0711 - val_accuracy: 0.7358 - val_loss: 1.0496\n",
      "Epoch 100/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7318 - loss: 1.0772 - val_accuracy: 0.7349 - val_loss: 1.0595\n",
      "Epoch 101/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7341 - loss: 1.0760 - val_accuracy: 0.7372 - val_loss: 1.0577\n",
      "Epoch 102/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7228 - loss: 1.0998 - val_accuracy: 0.7378 - val_loss: 1.0547\n",
      "Epoch 103/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7274 - loss: 1.0809 - val_accuracy: 0.7383 - val_loss: 1.0610\n",
      "Epoch 104/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7346 - loss: 1.0827 - val_accuracy: 0.7346 - val_loss: 1.0731\n",
      "Epoch 105/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7338 - loss: 1.0706 - val_accuracy: 0.7322 - val_loss: 1.0766\n",
      "Epoch 106/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7355 - loss: 1.0642 - val_accuracy: 0.7334 - val_loss: 1.0671\n",
      "Epoch 107/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7414 - loss: 1.0582 - val_accuracy: 0.7313 - val_loss: 1.0503\n",
      "Epoch 108/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7361 - loss: 1.0592 - val_accuracy: 0.7355 - val_loss: 1.0574\n",
      "Epoch 109/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7331 - loss: 1.0634 - val_accuracy: 0.7402 - val_loss: 1.0500\n",
      "Epoch 110/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7370 - loss: 1.0754 - val_accuracy: 0.7332 - val_loss: 1.0537\n",
      "Epoch 111/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7336 - loss: 1.0745 - val_accuracy: 0.7353 - val_loss: 1.0482\n",
      "Epoch 112/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7271 - loss: 1.0826 - val_accuracy: 0.7279 - val_loss: 1.0691\n",
      "Epoch 113/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7385 - loss: 1.0655 - val_accuracy: 0.7291 - val_loss: 1.0575\n",
      "Epoch 114/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7298 - loss: 1.0740 - val_accuracy: 0.7433 - val_loss: 1.0354\n",
      "Epoch 115/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7390 - loss: 1.0573 - val_accuracy: 0.7350 - val_loss: 1.0449\n",
      "Epoch 116/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7344 - loss: 1.0695 - val_accuracy: 0.7451 - val_loss: 1.0354\n",
      "Epoch 117/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7306 - loss: 1.0801 - val_accuracy: 0.7347 - val_loss: 1.0523\n",
      "Epoch 118/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7401 - loss: 1.0641 - val_accuracy: 0.7426 - val_loss: 1.0458\n",
      "Epoch 119/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7334 - loss: 1.0784 - val_accuracy: 0.7319 - val_loss: 1.0534\n",
      "Epoch 120/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7328 - loss: 1.0647 - val_accuracy: 0.7398 - val_loss: 1.0369\n",
      "Epoch 121/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7416 - loss: 1.0543 - val_accuracy: 0.7374 - val_loss: 1.0447\n",
      "Epoch 122/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7379 - loss: 1.0603 - val_accuracy: 0.7399 - val_loss: 1.0479\n",
      "Epoch 123/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7312 - loss: 1.0634 - val_accuracy: 0.7389 - val_loss: 1.0447\n",
      "Epoch 124/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7308 - loss: 1.0680 - val_accuracy: 0.7341 - val_loss: 1.0533\n",
      "Epoch 125/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7386 - loss: 1.0496 - val_accuracy: 0.7381 - val_loss: 1.0346\n",
      "Epoch 126/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7381 - loss: 1.0610 - val_accuracy: 0.7496 - val_loss: 1.0228\n",
      "Epoch 127/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7381 - loss: 1.0603 - val_accuracy: 0.7414 - val_loss: 1.0485\n",
      "Epoch 128/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7317 - loss: 1.0640 - val_accuracy: 0.7442 - val_loss: 1.0394\n",
      "Epoch 129/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7354 - loss: 1.0685 - val_accuracy: 0.7312 - val_loss: 1.0530\n",
      "Epoch 130/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7324 - loss: 1.0770 - val_accuracy: 0.7383 - val_loss: 1.0395\n",
      "Epoch 131/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7331 - loss: 1.0698 - val_accuracy: 0.7416 - val_loss: 1.0336\n",
      "Epoch 132/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7295 - loss: 1.0740 - val_accuracy: 0.7334 - val_loss: 1.0518\n",
      "Epoch 133/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7389 - loss: 1.0486 - val_accuracy: 0.7417 - val_loss: 1.0377\n",
      "Epoch 134/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7355 - loss: 1.0578 - val_accuracy: 0.7426 - val_loss: 1.0473\n",
      "Epoch 135/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7357 - loss: 1.0611 - val_accuracy: 0.7419 - val_loss: 1.0374\n",
      "Epoch 136/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7294 - loss: 1.0586 - val_accuracy: 0.7402 - val_loss: 1.0359\n",
      "Epoch 137/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7370 - loss: 1.0658 - val_accuracy: 0.7404 - val_loss: 1.0339\n",
      "Epoch 138/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7360 - loss: 1.0544 - val_accuracy: 0.7365 - val_loss: 1.0434\n",
      "Epoch 139/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.7263 - loss: 1.0780 - val_accuracy: 0.7401 - val_loss: 1.0327\n",
      "Epoch 140/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7395 - loss: 1.0520 - val_accuracy: 0.7393 - val_loss: 1.0386\n",
      "Epoch 141/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7297 - loss: 1.0683 - val_accuracy: 0.7338 - val_loss: 1.0465\n",
      "Epoch 142/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7309 - loss: 1.0581 - val_accuracy: 0.7364 - val_loss: 1.0389\n",
      "Epoch 143/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7369 - loss: 1.0551 - val_accuracy: 0.7401 - val_loss: 1.0384\n",
      "Epoch 144/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7343 - loss: 1.0550 - val_accuracy: 0.7422 - val_loss: 1.0259\n",
      "Epoch 145/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7365 - loss: 1.0494 - val_accuracy: 0.7358 - val_loss: 1.0442\n",
      "Epoch 146/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7289 - loss: 1.0709 - val_accuracy: 0.7362 - val_loss: 1.0510\n",
      "Epoch 147/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7350 - loss: 1.0690 - val_accuracy: 0.7326 - val_loss: 1.0473\n",
      "Epoch 148/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7351 - loss: 1.0521 - val_accuracy: 0.7378 - val_loss: 1.0479\n",
      "Epoch 149/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7291 - loss: 1.0634 - val_accuracy: 0.7378 - val_loss: 1.0476\n",
      "Epoch 150/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7329 - loss: 1.0625 - val_accuracy: 0.7401 - val_loss: 1.0363\n",
      "Epoch 151/200\n",
      "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7394 - loss: 1.0431 - val_accuracy: 0.7340 - val_loss: 1.0456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e782404e90>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model training\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=25,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "model.fit(X_train, y_train, epochs=200, validation_split=0.25, batch_size=32, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7291 - loss: 1.0669\n",
      "Test Accuracy: 0.73\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/fnn_dense_layers_encoder.pkl']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export the model and the encoder\n",
    "\n",
    "import joblib\n",
    "\n",
    "model.save('../models/fnn_dense_layers_model.keras')\n",
    "joblib.dump(encoder, '../models/fnn_dense_layers_encoder.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
